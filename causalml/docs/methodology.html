
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Methodology &#8212; MGTECON 634 at Stanford (Python scripts)</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">MGTECON 634 at Stanford (Python scripts)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../md/intro.html">
                    Machine Learning-Based Causal Inference
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../notebooks/1_introduction_1.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notebooks/2_introduction_to_machine_learning.html">
   2. Introduction to Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notebooks/3_average_treatment_effect_1.html">
   3. ATE I: Binary treatment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notebooks/4_heterogeneous_treatment_effect_1.html">
   4. HTE I: Binary treatment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notebooks/5_policy_evaluation_1.html">
   5. Policy Evaluation I - Binary Treatment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notebooks/6_policy_learning_1.html">
   6. Policy Learning I - Binary Treatment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notebooks/8_WGANs_for_simulation.html">
   7. Tutorial to simulate data using WGANs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notebooks/9_surrogate_py.html">
   8. The surrogate index Athey, S., et al. (2019).
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/d2cml-ai/mgtecon634_python"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/d2cml-ai/mgtecon634_python/issues/new?title=Issue%20on%20page%20%2Fcausalml/docs/methodology.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/d2cml-ai/mgtecon634_python/edit/master/_build/jupyter_execute/causalml/docs/methodology.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/causalml/docs/methodology.rst"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#meta-learner-algorithms">
   Meta-Learner Algorithms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#s-learner">
     S-Learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#t-learner">
     T-Learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#x-learner">
     X-Learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-learner">
     R-Learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#doubly-robust-dr-learner">
     Doubly Robust (DR) learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#doubly-robust-instrumental-variable-driv-learner">
     Doubly Robust Instrumental Variable (DRIV) learner
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tree-based-algorithms">
   Tree-Based Algorithms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#uplift-tree">
     Uplift Tree
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kl">
     KL
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ed">
     ED
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chi">
     Chi
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ddp">
     DDP
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cts">
     CTS
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#value-optimization-methods">
   Value optimization methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#counterfactual-unit-selection">
     Counterfactual Unit Selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#counterfactual-value-estimator">
     Counterfactual Value Estimator
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probabilities-of-causation">
   Probabilities of causation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#selected-traditional-methods">
   Selected traditional methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching">
     Matching
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inverse-probability-of-treatment-weighting">
     Inverse probability of treatment weighting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stage-least-squares-2sls">
     2-Stage Least Squares (2SLS)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#late">
     LATE
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#targeted-maximum-likelihood-estimation-tmle-for-ate">
   Targeted maximum likelihood estimation (TMLE) for ATE
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Methodology</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#meta-learner-algorithms">
   Meta-Learner Algorithms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#s-learner">
     S-Learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#t-learner">
     T-Learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#x-learner">
     X-Learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-learner">
     R-Learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#doubly-robust-dr-learner">
     Doubly Robust (DR) learner
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#doubly-robust-instrumental-variable-driv-learner">
     Doubly Robust Instrumental Variable (DRIV) learner
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tree-based-algorithms">
   Tree-Based Algorithms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#uplift-tree">
     Uplift Tree
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kl">
     KL
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ed">
     ED
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chi">
     Chi
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ddp">
     DDP
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cts">
     CTS
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#value-optimization-methods">
   Value optimization methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#counterfactual-unit-selection">
     Counterfactual Unit Selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#counterfactual-value-estimator">
     Counterfactual Value Estimator
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probabilities-of-causation">
   Probabilities of causation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#selected-traditional-methods">
   Selected traditional methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching">
     Matching
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inverse-probability-of-treatment-weighting">
     Inverse probability of treatment weighting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stage-least-squares-2sls">
     2-Stage Least Squares (2SLS)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#late">
     LATE
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#targeted-maximum-likelihood-estimation-tmle-for-ate">
   Targeted maximum likelihood estimation (TMLE) for ATE
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="methodology">
<h1>Methodology<a class="headerlink" href="#methodology" title="Permalink to this headline">#</a></h1>
<section id="meta-learner-algorithms">
<h2>Meta-Learner Algorithms<a class="headerlink" href="#meta-learner-algorithms" title="Permalink to this headline">#</a></h2>
<p>A meta-algorithm (or meta-learner) is a framework to estimate the Conditional Average Treatment Effect (CATE) using any machine learning estimators (called base learners) <span id="id1">[]</span>.</p>
<p>A meta-algorithm uses either a single base learner while having the treatment indicator as a feature (e.g. S-learner), or multiple base learners separately for each of the treatment and control groups (e.g. T-learner, X-learner and R-learner).</p>
<p>Confidence intervals of average treatment effect estimates are calculated based on the lower bound formular (7) from <span id="id2">[]</span>.</p>
<section id="s-learner">
<h3>S-Learner<a class="headerlink" href="#s-learner" title="Permalink to this headline">#</a></h3>
<p>S-learner estimates the treatment effect using a single machine learning model as follows:</p>
<p><strong>Stage 1</strong></p>
<p>Estimate the average outcomes <span class="math notranslate nohighlight">\(\mu(x)\)</span> with covariates <span class="math notranslate nohighlight">\(X\)</span> and an indicator variable for treatment <span class="math notranslate nohighlight">\(W\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mu(x,w) = E[Y \mid X=x, W=w]\]</div>
<p>using a machine learning model.</p>
<p><strong>Stage 2</strong></p>
<p>Define the CATE estimate as:</p>
<div class="math notranslate nohighlight">
\[\hat\tau(x) = \hat\mu(x, W=1) - \hat\mu(x, W=0)\]</div>
<p>Including the propensity score in the model can reduce bias from regularization induced confounding <span id="id3">[]</span>.</p>
<p>When the control and treatment groups are very different in covariates, a single linear model is not sufficient to encode the different relevant dimensions and smoothness of features for the control and treatment groups <span id="id4">[]</span>.</p>
</section>
<section id="t-learner">
<h3>T-Learner<a class="headerlink" href="#t-learner" title="Permalink to this headline">#</a></h3>
<p>T-learner <span id="id5">[]</span> consists of two stages as follows:</p>
<p><strong>Stage 1</strong></p>
<p>Estimate the average outcomes <span class="math notranslate nohighlight">\(\mu_0(x)\)</span> and <span class="math notranslate nohighlight">\(\mu_1(x)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mu_0(x) = E[Y(0)|X=x] \\
\mu_1(x) = E[Y(1)|X=x]\end{split}\]</div>
<p>using machine learning models.</p>
<p><strong>Stage 2</strong></p>
<p>Define the CATE estimate as:</p>
<div class="math notranslate nohighlight">
\[\hat\tau(x) = \hat\mu_1(x) - \hat\mu_0(x)\]</div>
</section>
<section id="x-learner">
<h3>X-Learner<a class="headerlink" href="#x-learner" title="Permalink to this headline">#</a></h3>
<p>X-learner <span id="id6">[]</span> is an extension of T-learner, and consists of three stages as follows:</p>
<p><strong>Stage 1</strong></p>
<p>Estimate the average outcomes <span class="math notranslate nohighlight">\(\mu_0(x)\)</span> and <span class="math notranslate nohighlight">\(\mu_1(x)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mu_0(x) = E[Y(0)|X=x] \\
\mu_1(x) = E[Y(1)|X=x]\end{split}\]</div>
<p>using machine learning models.</p>
<p><strong>Stage 2</strong></p>
<p>Impute the user level treatment effects, <span class="math notranslate nohighlight">\(D^1_i\)</span> and <span class="math notranslate nohighlight">\(D^0_j\)</span> for user <span class="math notranslate nohighlight">\(i\)</span> in the treatment group based on <span class="math notranslate nohighlight">\(\mu_0(x)\)</span>, and user <span class="math notranslate nohighlight">\(j\)</span> in the control groups based on <span class="math notranslate nohighlight">\(\mu_1(x)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}D^1_i = Y^1_i - \hat\mu_0(X^1_i) \\
D^0_i = \hat\mu_1(X^0_i) - Y^0_i\end{split}\]</div>
<p>then estimate <span class="math notranslate nohighlight">\(\tau_1(x) = E[D^1|X=x]\)</span>, and <span class="math notranslate nohighlight">\(\tau_0(x) = E[D^0|X=x]\)</span> using machine learning models.</p>
<p><strong>Stage 3</strong></p>
<p>Define the CATE estimate by a weighted average of <span class="math notranslate nohighlight">\(\tau_1(x)\)</span> and <span class="math notranslate nohighlight">\(\tau_0(x)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\tau(x) = g(x)\tau_0(x) + (1 - g(x))\tau_1(x)\]</div>
<p>where <span class="math notranslate nohighlight">\(g \in [0, 1]\)</span>. We can use propensity scores for <span class="math notranslate nohighlight">\(g(x)\)</span>.</p>
</section>
<section id="r-learner">
<h3>R-Learner<a class="headerlink" href="#r-learner" title="Permalink to this headline">#</a></h3>
<p>R-learner <span id="id7">[]</span> uses the cross-validation out-of-fold estimates of outcomes <span class="math notranslate nohighlight">\(\hat{m}^{(-i)}(x_i)\)</span> and propensity scores <span class="math notranslate nohighlight">\(\hat{e}^{(-i)}(x_i)\)</span>. It consists of two stages as follows:</p>
<p><strong>Stage 1</strong></p>
<p>Fit <span class="math notranslate nohighlight">\(\hat{m}(x)\)</span> and <span class="math notranslate nohighlight">\(\hat{e}(x)\)</span> with machine learning models using cross-validation.</p>
<p><strong>Stage 2</strong></p>
<p>Estimate treatment effects by minimising the R-loss, <span class="math notranslate nohighlight">\(\hat{L}_n(\tau(x))\)</span>:</p>
<div class="math notranslate nohighlight">
\[\hat{L}_n(\tau(x)) = \frac{1}{n} \sum^n_{i=1}\big(\big(Y_i - \hat{m}^{(-i)}(X_i)\big) - \big(W_i - \hat{e}^{(-i)}(X_i)\big)\tau(X_i)\big)^2\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{e}^{(-i)}(X_i)\)</span>, etc. denote the out-of-fold held-out predictions made without using the <span class="math notranslate nohighlight">\(i\)</span>-th training sample.</p>
</section>
<section id="doubly-robust-dr-learner">
<h3>Doubly Robust (DR) learner<a class="headerlink" href="#doubly-robust-dr-learner" title="Permalink to this headline">#</a></h3>
<p>DR-learner <span id="id8">[]</span> estimates the CATE via cross-fitting a doubly-robust score function in two stages as follows. We start by randomly split the data <span class="math notranslate nohighlight">\(\{Y, X, W\}\)</span> into 3 partitions <span class="math notranslate nohighlight">\(\{Y^i, X^i, W^i\}, i=\{1,2,3\}\)</span>.</p>
<p><strong>Stage 1</strong></p>
<p>Fit a propensity score model <span class="math notranslate nohighlight">\(\hat{e}(x)\)</span> with machine learning using <span class="math notranslate nohighlight">\(\{X^1, W^1\}\)</span>, and fit outcome regression models <span class="math notranslate nohighlight">\(\hat{m}_0(x)\)</span> and <span class="math notranslate nohighlight">\(\hat{m}_1(x)\)</span> for treated and untreated users with machine learning using <span class="math notranslate nohighlight">\(\{Y^2, X^2, W^2\}\)</span>.</p>
<p><strong>Stage 2</strong></p>
<p>Use machine learning to fit the CATE model, <span class="math notranslate nohighlight">\(\hat{\tau}(X)\)</span> from the pseudo-outcome</p>
<div class="math notranslate nohighlight">
\[\phi = \frac{W-\hat{e}(X)}{\hat{e}(X)(1-\hat{e}(X))}\left(Y-\hat{m}_W(X)\right)+\hat{m}_1(X)-\hat{m}_0(X)\]</div>
<p>with <span class="math notranslate nohighlight">\(\{Y^3, X^3, W^3\}\)</span></p>
<p><strong>Stage 3</strong></p>
<p>Repeat Stage 1 and Stage 2 again twice. First use <span class="math notranslate nohighlight">\(\{Y^2, X^2, W^2\}\)</span>, <span class="math notranslate nohighlight">\(\{Y^3, X^3, W^3\}\)</span>, and <span class="math notranslate nohighlight">\(\{Y^1, X^1, W^1\}\)</span> for the propensity score model, the outcome models, and the CATE model. Then use <span class="math notranslate nohighlight">\(\{Y^3, X^3, W^3\}\)</span>, <span class="math notranslate nohighlight">\(\{Y^2, X^2, W^2\}\)</span>, and <span class="math notranslate nohighlight">\(\{Y^1, X^1, W^1\}\)</span> for the propensity score model, the outcome models, and the CATE model. The final CATE model is the average of the 3 CATE models.</p>
</section>
<section id="doubly-robust-instrumental-variable-driv-learner">
<h3>Doubly Robust Instrumental Variable (DRIV) learner<a class="headerlink" href="#doubly-robust-instrumental-variable-driv-learner" title="Permalink to this headline">#</a></h3>
<p>We combine the idea from DR-learner <span id="id9">[]</span> with the doubly robust score function for LATE described in <span id="id10">[]</span> to estimate the conditional LATE. Towards that end, we start by randomly split the data <span class="math notranslate nohighlight">\(\{Y, X, W, Z\}\)</span> into 3 partitions <span class="math notranslate nohighlight">\(\{Y^i, X^i, W^i, Z^i\}, i=\{1,2,3\}\)</span>.</p>
<p><strong>Stage 1</strong></p>
<p>Fit propensity score models <span class="math notranslate nohighlight">\(\hat{e}_0(x)\)</span> and <span class="math notranslate nohighlight">\(\hat{e}_1(x)\)</span> for assigned and unassigned users using <span class="math notranslate nohighlight">\(\{X^1, W^1, Z^1\}\)</span>, and fit outcome regression models <span class="math notranslate nohighlight">\(\hat{m}_0(x)\)</span> and <span class="math notranslate nohighlight">\(\hat{m}_1(x)\)</span> for assigned and unassigned users with machine learning using <span class="math notranslate nohighlight">\(\{Y^2, X^2, Z^2\}\)</span>. Assignment probabiliy, <span class="math notranslate nohighlight">\(p_Z\)</span>, can either be user provided or come from a simple model, since in most use cases assignment is random by design.</p>
<p><strong>Stage 2</strong></p>
<p>Use machine learning to fit the conditional <span class="xref std std-ref">LATE</span> model, <span class="math notranslate nohighlight">\(\hat{\tau}(X)\)</span> by minimizing the following loss function</p>
<div class="math notranslate nohighlight">
\[\begin{split}L(\hat{\tau}(X)) = \hat{E} &amp;\left[\left(\hat{m}_1(X)-\hat{m}_0(X)+\frac{Z(Y-\hat{m}_1(X))}{p_Z}-\frac{(1-Z)(Y-\hat{m}_0(X))}{1-p_Z} \right.\right.\\
&amp;\left.\left.\quad -\Big(\hat{e}_1(X)-\hat{e}_0(X)+\frac{Z(W-\hat{e}_1(X))}{p_Z}-\frac{(1-Z)(W-\hat{e}_0(X))}{1-p_Z}\Big) \hat{\tau}(X) \right)^2\right]\end{split}\]</div>
<p>with <span class="math notranslate nohighlight">\(\{Y^3, X^3, W^3\}\)</span></p>
<p><strong>Stage 3</strong></p>
<p>Similar to the DR-Learner Repeat Stage 1 and Stage 2 again twice with different permutations of partitions for estimation. The final conditional LATE model is the average of the 3 conditional LATE models.</p>
</section>
</section>
<section id="tree-based-algorithms">
<h2>Tree-Based Algorithms<a class="headerlink" href="#tree-based-algorithms" title="Permalink to this headline">#</a></h2>
<section id="uplift-tree">
<h3>Uplift Tree<a class="headerlink" href="#uplift-tree" title="Permalink to this headline">#</a></h3>
<p>The Uplift Tree approach consists of a set of methods that use a tree-based algorithm where the splitting criterion is based on differences in uplift. <span id="id11">[]</span> proposed three different ways to quantify the gain in divergence as the result of splitting <span id="id12">[]</span>:</p>
<div class="math notranslate nohighlight">
\[D_{gain} = D_{after_{split}} (P^T, P^C) - D_{before_{split}}(P^T, P^C)\]</div>
<p>where <span class="math notranslate nohighlight">\(D\)</span> measures the divergence and <span class="math notranslate nohighlight">\(P^T\)</span> and <span class="math notranslate nohighlight">\(P^C\)</span> refer to the probability distribution of the outcome of interest in the treatment and control groups, respectively. Three different ways to quantify the divergence, KL, ED and Chi, are implemented in the package.</p>
</section>
<section id="kl">
<h3>KL<a class="headerlink" href="#kl" title="Permalink to this headline">#</a></h3>
<p>The Kullback-Leibler (KL) divergence is given by:</p>
<div class="math notranslate nohighlight">
\[KL(P : Q) = \sum_{k=left, right}p_klog\frac{p_k}{q_k}\]</div>
<p>where <span class="math notranslate nohighlight">\(p\)</span> is the sample mean in the treatment group, <span class="math notranslate nohighlight">\(q\)</span> is the sample mean in the control group and <span class="math notranslate nohighlight">\(k\)</span> indicates the leaf in which <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span> are computed <span id="id13">[]</span></p>
</section>
<section id="ed">
<h3>ED<a class="headerlink" href="#ed" title="Permalink to this headline">#</a></h3>
<p>The Euclidean Distance is given by:</p>
<div class="math notranslate nohighlight">
\[ED(P : Q) = \sum_{k=left, right}(p_k - q_k)^2\]</div>
<p>where the notation is the same as above.</p>
</section>
<section id="chi">
<h3>Chi<a class="headerlink" href="#chi" title="Permalink to this headline">#</a></h3>
<p>Finally, the <span class="math notranslate nohighlight">\(\chi^2\)</span>-divergence is given by:</p>
<div class="math notranslate nohighlight">
\[\chi^2(P : Q) = \sum_{k=left, right}\frac{(p_k - q_k)^2}{q_k}\]</div>
<p>where the notation is again the same as above.</p>
</section>
<section id="ddp">
<h3>DDP<a class="headerlink" href="#ddp" title="Permalink to this headline">#</a></h3>
<p>Another Uplift Tree algorithm that is implemented is the delta-delta-p (<span class="math notranslate nohighlight">\(\Delta\Delta P\)</span>) approach by <span id="id14">[]</span>, where the sample splitting criterion is defined as follows:</p>
<div class="math notranslate nohighlight">
\[\Delta\Delta P=|(P^T(y|a_0)-P^C(y|a_0) - (P^T(y|a_1)-P^C(y|a_1)))|\]</div>
<p>where <span class="math notranslate nohighlight">\(a_0\)</span> and <span class="math notranslate nohighlight">\(a_1\)</span> are the outcomes of a Split A, <span class="math notranslate nohighlight">\(y\)</span> is the selected class, and <span class="math notranslate nohighlight">\(P^T\)</span> and <span class="math notranslate nohighlight">\(P^C\)</span> are the response rates of treatment and control group, respectively. In other words, we first calculate the difference in the response rate in each branch (<span class="math notranslate nohighlight">\(\Delta P_{left}\)</span> and <span class="math notranslate nohighlight">\(\Delta P_{right}\)</span>), and subsequently, calculate their differences (<span class="math notranslate nohighlight">\(\Delta\Delta P = |\Delta P_{left} - \Delta P_{right}|\)</span>).</p>
</section>
<section id="cts">
<h3>CTS<a class="headerlink" href="#cts" title="Permalink to this headline">#</a></h3>
<p>The final Uplift Tree algorithm that is implemented is the Contextual Treatment Selection (CTS) approach by <span id="id15">[]</span>, where the sample splitting criterion is defined as follows:</p>
<div class="math notranslate nohighlight">
\[\hat{\Delta}_{\mu}(s) = \hat{p}(\phi_l \mid \phi) \times \max_{t=0, ..., K}\hat{y}_t(\phi_l) + \hat{p}(\phi_r \mid \phi) \times \max_{t=0, ..., K}\hat{y}_t(\phi_r) -  \max_{t=0, ..., K}\hat{y}_t(\phi)\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi_l\)</span> and <span class="math notranslate nohighlight">\(\phi_r\)</span> refer to the feature subspaces in the left leaf and the right leaves respectively, <span class="math notranslate nohighlight">\(\hat{p}(\phi_j \mid \phi)\)</span> denotes the estimated conditional probability of a subject’s being in <span class="math notranslate nohighlight">\(\phi_j\)</span> given <span class="math notranslate nohighlight">\(\phi\)</span>, and <span class="math notranslate nohighlight">\(\hat{y}_t(\phi_j)\)</span> is the conditional expected response under treatment <span class="math notranslate nohighlight">\(t\)</span>.</p>
</section>
</section>
<section id="value-optimization-methods">
<h2>Value optimization methods<a class="headerlink" href="#value-optimization-methods" title="Permalink to this headline">#</a></h2>
<p>The package supports methods for assigning treatment groups when treatments are costly. To understand the problem, it is helpful to divide populations into the following four categories:</p>
<ul class="simple">
<li><p><strong>Compliers</strong>. Those who will have a favourable outcome if and only if they are treated.</p></li>
<li><p><strong>Always-takers</strong>. Those who will have a favourable outcome whether or not they are treated.</p></li>
<li><p><strong>Never-takers</strong>. Those who will never have a favourable outcome whether or not they are treated.</p></li>
<li><p><strong>Defiers</strong>. Those who will have a favourable outcome if and only if they are not treated.</p></li>
</ul>
<p>For a more detailed discussion see e.g. <span id="id16">[]</span>.</p>
<section id="counterfactual-unit-selection">
<h3>Counterfactual Unit Selection<a class="headerlink" href="#counterfactual-unit-selection" title="Permalink to this headline">#</a></h3>
<p><span id="id17">[]</span> propose a method for selecting units for treatments using counterfactual logic. Suppose the following benefits for selecting units belonging to the different categories above:</p>
<ul class="simple">
<li><p>Compliers: <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
<li><p>Always-takers: <span class="math notranslate nohighlight">\(\gamma\)</span></p></li>
<li><p>Never-takers: <span class="math notranslate nohighlight">\(\theta\)</span></p></li>
<li><p>Defiers: <span class="math notranslate nohighlight">\(\delta\)</span></p></li>
</ul>
<p>If <span class="math notranslate nohighlight">\(X\)</span> denotes the set of individual’s features, the unit selection problem can be formulated as follows:</p>
<div class="math notranslate nohighlight">
\[argmax_X \beta P(\text{complier} \mid X) + \gamma P(\text{always-taker} \mid X) + \theta P(\text{never-taker} \mid X) + \delta P(\text{defier} \mid X)\]</div>
<p>The problem can be reformulated using counterfactual logic. Suppose <span class="math notranslate nohighlight">\(W = w\)</span> indicates that an individual is treated and <span class="math notranslate nohighlight">\(W = w'\)</span> indicates he or she is untreated. Similarly, let <span class="math notranslate nohighlight">\(F = f\)</span> denote a favourable outcome for the individual and <span class="math notranslate nohighlight">\(F = f'\)</span> an unfavourable outcome. Then the optimization problem becomes:</p>
<div class="math notranslate nohighlight">
\[argmax_X \beta P(f_w, f'_{w'} \mid X) + \gamma P(f_w, f_{w'} \mid X) + \theta P(f'_w, f'_{w'} \mid X) + \delta P(f_{w'}, f'_{w} \mid X)\]</div>
<p>Note that the above simply follows from the definitions of the relevant users segments. <span id="id18">[]</span> then use counterfactual logic (<span id="id19">[]</span>) to solve the above optimization problem under certain conditions.</p>
<p>N.B. The current implementation in the package is highly experimental.</p>
</section>
<section id="counterfactual-value-estimator">
<h3>Counterfactual Value Estimator<a class="headerlink" href="#counterfactual-value-estimator" title="Permalink to this headline">#</a></h3>
<p>The counterfactual value estimation method implemented in the package predicts the outcome for a unit under different treatment conditions using a standard machine learning model. The expected value of assigning a unit into a particular treatment is then given by</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[(v - cc_w)Y_w - ic_w]\]</div>
<p>where <span class="math notranslate nohighlight">\(Y_w\)</span> is the probability of a favourable event (such as conversion) under a given treatment <span class="math notranslate nohighlight">\(w\)</span>, <span class="math notranslate nohighlight">\(v\)</span> is the value of the favourable event, <span class="math notranslate nohighlight">\(cc_w\)</span> is the cost of the treatment triggered in case of a favourable event, and <span class="math notranslate nohighlight">\(ic_w\)</span> is the cost associated with the treatment whether or not the outcome is favourable. This method builds upon the ideas discussed in <span id="id20">[]</span>.</p>
</section>
</section>
<section id="probabilities-of-causation">
<h2>Probabilities of causation<a class="headerlink" href="#probabilities-of-causation" title="Permalink to this headline">#</a></h2>
<p>A cause is said to be <em>necessary</em> for an outcome if the outcome would not have occurred in the absence of the cause. A cause is said to be <em>sufficient</em> for an outcome if the outcome would have occurred in the presence of the cause. A cause is said to be <em>necessary and sufficient</em> if both of the above two conditions hold. <span id="id21">[]</span> show that we can calculate bounds for the probability that a cause is of each of the above three types.</p>
<p>To understand how the bounds for the probabilities of causation are calculated, we need special notation to represent counterfactual quantities. Let <span class="math notranslate nohighlight">\(y_t\)</span> represent the proposition “<span class="math notranslate nohighlight">\(y\)</span> would occur if the treatment group was set to ‘treatment’”, <span class="math notranslate nohighlight">\(y^{\prime}_c\)</span> represent the proposition “<span class="math notranslate nohighlight">\(y\)</span> would not occur if the treatment group was set to ‘control’”, and similarly for the remaining two combinations of the (by assumption) binary outcome and treatment variables.</p>
<p>Then the probability that the treatment is <em>sufficient</em> for <span class="math notranslate nohighlight">\(y\)</span> to occur can be defined as</p>
<div class="math notranslate nohighlight">
\[PS = P(y_t \mid c, y^{\prime})\]</div>
<p>This is the probability that the <span class="math notranslate nohighlight">\(y\)</span> would occur if the treatment was set to <span class="math notranslate nohighlight">\(t\)</span> when in fact the treatment was set to control and the outcome did not occur.</p>
<p>The probability that the treatment is <em>necessary</em> for <span class="math notranslate nohighlight">\(y\)</span> to occur can be defined as</p>
<div class="math notranslate nohighlight">
\[PN = P(y^{\prime}_c \mid t, y)\]</div>
<p>This is the probability that <span class="math notranslate nohighlight">\(y\)</span> would not occur if the treatment was set to control, while in actuality both <span class="math notranslate nohighlight">\(y\)</span> occurs and the treatment takes place.</p>
<p>Finally, the probability that the treatment is both necessary and sufficient is defined as</p>
<div class="math notranslate nohighlight">
\[PNS = P(y_t, y^{\prime}_c)\]</div>
<p>and states that <span class="math notranslate nohighlight">\(y\)</span> would occur if the treatment took place; and <span class="math notranslate nohighlight">\(y\)</span> would not occur if the treatment did not take place. PNS is related with PN and PS as follows:</p>
<div class="math notranslate nohighlight">
\[PNS = P(t, y)PN + P(c, y^{\prime})PS\]</div>
<p>In bounding the above three quantities, we utilize observational data in addition to experimental data. The observational data is characterized in terms of the joint probabilities:</p>
<div class="math notranslate nohighlight">
\[P_{TY} = {P(t, y),  P(c, y), P(t, y^{\prime}), P(c, y^{\prime})}\]</div>
<p>Given this, <span id="id22">[]</span> use the program developed in <span id="id23">[]</span> to obtain sharp bounds of the above three quantities. The main idea in this program is to turn the bounding task into a linear programming problem (for a modern implementation of their approach see <a class="reference external" href="https://cran.r-project.org/web/packages/causaloptim/vignettes/vertexenum-speed.html">here</a>).</p>
<p>Using the linear programming approach and given certain constraints together with observational data, <span id="id24">[]</span> find that the shar lower bound for PNS is given by</p>
<div class="math notranslate nohighlight">
\[max\{0, P(y_t) - P(y_c), P(y) - P(y_c), P(y_t) - P(y)\}\]</div>
<p>and the sharp upper bound is given by</p>
<div class="math notranslate nohighlight">
\[min\{P(y_t), P(y^{\prime}_c), P(t, y) + P(c, y^{\prime}), P(y_t) - P(y_c) + P(t, y^{\prime}) + P(c, y)\}\]</div>
<p>They use a similar routine to find the bounds for PS and PN. The <cite>get_pns_bounds()</cite> function calculates the bounds for each of the three probabilities of causation using the results in <span id="id25">[]</span>.</p>
</section>
<section id="selected-traditional-methods">
<h2>Selected traditional methods<a class="headerlink" href="#selected-traditional-methods" title="Permalink to this headline">#</a></h2>
<p>The package supports selected traditional causal inference methods. These are usually used to conduct causal inference with observational (non-experimental) data. In these types of studies, the observed difference between the treatment and the control is in general not equal to the difference between “potential outcomes” <span class="math notranslate nohighlight">\(\mathbb{E}[Y(1) - Y(0)]\)</span>. Thus, the methods below try to deal with this problem in different ways.</p>
<section id="matching">
<h3>Matching<a class="headerlink" href="#matching" title="Permalink to this headline">#</a></h3>
<p>The general idea in matching is to find treated and non-treated units that are as similar as possible in terms of their relevant characteristics. As such, matching methods can be seen as part of the family of causal inference approaches that try to mimic randomized controlled trials.</p>
<p>While there are a number of different ways to match treated and non-treated units, the most common method is to use the propensity score:</p>
<div class="math notranslate nohighlight">
\[e_i(X_i) = P(W_i = 1 \mid X_i)\]</div>
<p>Treated and non-treated units are then matched in terms of <span class="math notranslate nohighlight">\(e(X)\)</span> using some criterion of distance, such as <span class="math notranslate nohighlight">\(k:1\)</span> nearest neighbours. Because matching is usually between the treated population and the control, this method estimates the average treatment effect on the treated (ATT):</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[Y(1) \mid W = 1] - \mathbb{E}[Y(0) \mid W = 1]\]</div>
<p>See <span id="id26">[]</span> for a discussion of the strengths and weaknesses of the different matching methods.</p>
</section>
<section id="inverse-probability-of-treatment-weighting">
<h3>Inverse probability of treatment weighting<a class="headerlink" href="#inverse-probability-of-treatment-weighting" title="Permalink to this headline">#</a></h3>
<p>The inverse probability of treatment weighting (IPTW) approach uses the propensity score <span class="math notranslate nohighlight">\(e\)</span> to weigh the treated and non-treated populations by the inverse of the probability of the actual treatment <span class="math notranslate nohighlight">\(W\)</span>. For a binary treatment <span class="math notranslate nohighlight">\(W \in \{1, 0\}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\frac{W}{e} + \frac{1 - W}{1 - e}\]</div>
<p>In this way, the IPTW approach can be seen as creating an artificial population in which the treated and non-treated units are similar in terms of their observed features <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>One of the possible benefits of IPTW compared to matching is that less data may be discarded due to lack of overlap between treated and non-treated units. A known problem with the approach is that extreme propensity scores can generate highly variable estimators. Different methods have been proposed for trimming and normalizing the IPT weights (<span id="id27">[]</span>). An overview of the IPTW approach can be found in <span id="id28">[]</span>.</p>
</section>
<section id="stage-least-squares-2sls">
<h3>2-Stage Least Squares (2SLS)<a class="headerlink" href="#stage-least-squares-2sls" title="Permalink to this headline">#</a></h3>
<p>One of the basic requirements for identifying the treatment effect of <span class="math notranslate nohighlight">\(W\)</span> on <span class="math notranslate nohighlight">\(Y\)</span> is that <span class="math notranslate nohighlight">\(W\)</span> is orthogonal to the potential outcome of <span class="math notranslate nohighlight">\(Y\)</span>, conditional on the covariates <span class="math notranslate nohighlight">\(X\)</span>. This may be violated if both <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are affected by an unobserved variable, the error term after removing the true effect of <span class="math notranslate nohighlight">\(W\)</span> from <span class="math notranslate nohighlight">\(Y\)</span>, that is not in <span class="math notranslate nohighlight">\(X\)</span>. In this case, the instrumental variables approach attempts to estimate the effect of <span class="math notranslate nohighlight">\(W\)</span> on <span class="math notranslate nohighlight">\(Y\)</span> with the help of a third variable <span class="math notranslate nohighlight">\(Z\)</span> that is correlated with <span class="math notranslate nohighlight">\(W\)</span> but is uncorrelated with the error term. In other words, the instrument <span class="math notranslate nohighlight">\(Z\)</span> is only related with <span class="math notranslate nohighlight">\(Y\)</span> through the directed path that goes through <span class="math notranslate nohighlight">\(W\)</span>. If these conditions are satisfied, in the case without covariates, the effect of <span class="math notranslate nohighlight">\(W\)</span> on <span class="math notranslate nohighlight">\(Y\)</span> can be estimated using the sample analog of:</p>
<div class="math notranslate nohighlight">
\[\frac{Cov(Y_i, Z_i)}{Cov(W_i, Z_i)}\]</div>
<p>The most common method for instrumental variables estimation is the two-stage least squares (2SLS). In this approach, the cause variable <span class="math notranslate nohighlight">\(W\)</span> is first regressed on the instrument <span class="math notranslate nohighlight">\(Z\)</span>. Then, in the second stage, the outcome of interest <span class="math notranslate nohighlight">\(Y\)</span> is regressed on the predicted value from the first-stage model. Intuitively, the effect of <span class="math notranslate nohighlight">\(W\)</span> on <span class="math notranslate nohighlight">\(Y\)</span> is estimated by using only the proportion of variation in <span class="math notranslate nohighlight">\(W\)</span> due to variation in <span class="math notranslate nohighlight">\(Z\)</span>. Specifically, assume that we have the linear model</p>
<div class="math notranslate nohighlight">
\[Y = W \alpha + X \beta + u = \Xi \gamma + u\]</div>
<p>Here for convenience we let <span class="math notranslate nohighlight">\(\Xi=[W, X]\)</span> and <span class="math notranslate nohighlight">\(\gamma=[\alpha', \beta']'\)</span>. Assume that we have instrumental variables <span class="math notranslate nohighlight">\(Z\)</span> whose number of columns is at least the number of columns of <span class="math notranslate nohighlight">\(W\)</span>, let <span class="math notranslate nohighlight">\(\Omega=[Z, X]\)</span>, 2SLS estimator is as follows</p>
<div class="math notranslate nohighlight">
\[\hat{\gamma}_{2SLS} = \left[\Xi'\Omega (\Omega'\Omega)^{-1} \Omega' \Xi\right]^{-1}\left[\Xi'\Omega'(\Omega'\Omega)^{-1}\Omega'Y\right].\]</div>
<p>See <span id="id29">[]</span> for a detailed discussion of the method.</p>
</section>
<section id="late">
<h3>LATE<a class="headerlink" href="#late" title="Permalink to this headline">#</a></h3>
<p>In many situations the treatment <span class="math notranslate nohighlight">\(W\)</span> may depend on subject’s own choice and cannot be administered directly in an experimental setting. However one can randomly assign users into treatment/control groups so that users in the treatment group can be nudged to take the treatment. This is the case of noncompliance, where users may fail to comply with their assignment status, <span class="math notranslate nohighlight">\(Z\)</span>, as to whether to take treatment or not. Similar to the section of Value optimization methods, in general there are 3 types of users in this situation,</p>
<ul class="simple">
<li><p><strong>Compliers</strong> Those who will take the treatment if and only if they are assigned to the treatment group.</p></li>
<li><p><strong>Always-Taker</strong> Those who will take the treatment regardless which group they are assigned to.</p></li>
<li><p><strong>Never-Taker</strong> Those who wil not take the treatment regardless which group they are assigned to.</p></li>
</ul>
<p>However one assumes that there is no Defier for identification purposes, i.e. those who will only take the treatment if they are assigned to the control group.</p>
<p>In this case one can measure the treatment effect of Compliers,</p>
<div class="math notranslate nohighlight">
\[\hat{\tau}_{Complier}=\frac{E[Y|Z=1]-E[Y|Z=0]}{E[W|Z=1]-E[W|Z=0]}\]</div>
<p>This is Local Average Treatment Effect (LATE). The estimator is also equivalent to 2SLS if we take the assignment status, <span class="math notranslate nohighlight">\(Z\)</span>, as an instrument.</p>
</section>
</section>
<section id="targeted-maximum-likelihood-estimation-tmle-for-ate">
<h2>Targeted maximum likelihood estimation (TMLE) for ATE<a class="headerlink" href="#targeted-maximum-likelihood-estimation-tmle-for-ate" title="Permalink to this headline">#</a></h2>
<p>Targeted maximum likelihood estimation (TMLE) <span id="id30">[]</span> provides a doubly robust semiparametric method that “targets” directly on the average treatment effect with the aid from machine learning algorithms. Compared to other methods including outcome regression and inverse probability of treatment weighting, TMLE usually gives better performance especially when dealing with skewed treatment and outliers.</p>
<p>Given binary treatment <span class="math notranslate nohighlight">\(W\)</span>, covariates <span class="math notranslate nohighlight">\(X\)</span>, and outcome <span class="math notranslate nohighlight">\(Y\)</span>, the TMLE for ATE is performed in the following steps</p>
<p><strong>Step 1</strong></p>
<p>Use cross fit to estimate the propensity score <span class="math notranslate nohighlight">\(\hat{e}(x)\)</span>, the predicted outcome for treated <span class="math notranslate nohighlight">\(\hat{m}_1(x)\)</span>, and predicted outcome for control <span class="math notranslate nohighlight">\(\hat{m}_0(x)\)</span> with machine learning.</p>
<p><strong>Step 2</strong></p>
<p>Scale <span class="math notranslate nohighlight">\(Y\)</span> into <span class="math notranslate nohighlight">\(\tilde{Y}=\frac{Y-\min Y}{\max Y - \min Y}\)</span> so that <span class="math notranslate nohighlight">\(\tilde{Y} \in [0,1]\)</span>. Use the same scale function to transform <span class="math notranslate nohighlight">\(\hat{m}_i(x)\)</span> into <span class="math notranslate nohighlight">\(\tilde{m}_i(x)\)</span>, <span class="math notranslate nohighlight">\(i=0,1\)</span>. Clip the scaled functions so that their values stay in the unit interval.</p>
<p><strong>Step 3</strong></p>
<p>Let <span class="math notranslate nohighlight">\(Q=\log(\tilde{m}_W(X)/(1-\tilde{m}_W(X)))\)</span>. Maximize the following pseudo log-likelihood function</p>
<div class="math notranslate nohighlight">
\[\begin{split}\max_{h_0, h_1} -\frac{1}{N} \sum_i &amp; \left[ \tilde{Y}_i \log \left(1+\exp(-Q_i-h_0 \frac{1-W}{1-\hat{e}(X_i)}-h_1 \frac{W}{\hat{e}(X_i)} \right) \right. \\
&amp;\quad\left.+(1-\tilde{Y}_i)\log\left(1+\exp(Q_i+h_0\frac{1-W}{1-\hat{e}(X_i)}+h_1\frac{W}{\hat{e}(X_i)}\right)\right]\end{split}\]</div>
<p><strong>Step 4</strong></p>
<p>Let</p>
<div class="math notranslate nohighlight">
\[\begin{split}\tilde{Q}_0 &amp;= \frac{1}{1+\exp\left(-Q-h_0 \frac{1}{1-\hat{e}(X)}\right)},\\
\tilde{Q}_1 &amp;= \frac{1}{1+\exp\left(-Q-h_1 \frac{1}{\hat{e}(X)}\right)}.\end{split}\]</div>
<p>The ATE estimate is the sample average of the differences of <span class="math notranslate nohighlight">\(\tilde{Q}_1\)</span> and <span class="math notranslate nohighlight">\(\tilde{Q}_0\)</span> after rescale to the original range.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "d2cml-ai/mgtecon634_python",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./causalml/docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Phd Susan Athey<br/>
  
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>